{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data file... Please wait...\n",
      "Successfully loaded 3.6 G bin file!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'raw_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-27f6cb9584d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0muserInput1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Type the phrase1: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m                 \u001b[0muserInput2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Type the phrase2: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'raw_input' is not defined"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Loading word2vec\n",
    "######################\n",
    "import gensim\n",
    "# from gensim.models import word2vec\n",
    "# Change this to your own path.\n",
    "pathToBinVectors = 'GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "print (\"Loading the data file... Please wait...\")\n",
    "model1 = gensim.models.KeyedVectors.load_word2vec_format(pathToBinVectors, binary=True)\n",
    "print (\"Successfully loaded 3.6 G bin file!\")\n",
    "\n",
    "# How to call one word vector?\n",
    "# model1['resume'] -> This will return NumPy vector of the word \"resume\".\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from random import sample\n",
    "import sys\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "class PhraseVector:\n",
    "\tdef __init__(self, phrase):\n",
    "\t\tself.vector = self.PhraseToVec(phrase)\n",
    "\t# <summary> Calculates similarity between two sets of vectors based on the averages of the sets.</summary>\n",
    "\t# <param>name = \"vectorSet\" description = \"An array of arrays that needs to be condensed into a single array (vector). In this class, used to convert word vecs to phrases.\"</param>\n",
    "\t# <param>name = \"ignore\" description = \"The vectors within the set that need to be ignored. If this is an empty list, nothing is ignored. In this class, this would be stop words.\"</param>\n",
    "\t# <returns> The condensed single vector that has the same dimensionality as the other vectors within the vecotSet.</returns>\n",
    "\tdef ConvertVectorSetToVecAverageBased(self, vectorSet, ignore = []):\n",
    "\t\tif len(ignore) == 0: \n",
    "\t\t\treturn np.mean(vectorSet, axis = 0)\n",
    "\t\telse: \n",
    "\t\t\treturn np.dot(np.transpose(vectorSet),ignore)/sum(ignore)\n",
    "\n",
    "\tdef PhraseToVec(self, phrase):\n",
    "\t\tcachedStopWords = stopwords.words(\"english\")\n",
    "\t\tphrase = phrase.lower()\n",
    "\t\twordsInPhrase = [word for word in phrase.split() if word not in cachedStopWords]\n",
    "\t\tvectorSet = []\n",
    "\t\tfor aWord in wordsInPhrase:\n",
    "\t\t\ttry:\n",
    "\t\t\t\twordVector=model1[aWord]\n",
    "\t\t\t\tvectorSet.append(wordVector)\n",
    "\t\t\texcept:\n",
    "\t\t\t\tpass\n",
    "\t\treturn self.ConvertVectorSetToVecAverageBased(vectorSet)\n",
    "\n",
    "\t# <summary> Calculates Cosine similarity between two phrase vectors.</summary>\n",
    "\t# <param> name = \"otherPhraseVec\" description = \"The other vector relative to which similarity is to be calculated.\"</param>\n",
    "\tdef CosineSimilarity(self, otherPhraseVec):\n",
    "\t\tcosine_similarity = np.dot(self.vector, otherPhraseVec) / (np.linalg.norm(self.vector) * np.linalg.norm(otherPhraseVec))\n",
    "\t\ttry:\n",
    "\t\t\tif math.isnan(cosine_similarity):\n",
    "\t\t\t\tcosine_similarity=0\n",
    "\t\texcept:\n",
    "\t\t\tcosine_similarity=0\n",
    "\t\treturn cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score:  0.30424094\n"
     ]
    }
   ],
   "source": [
    "userInput1 = \"I am currently a Singtel Home Broadband subscriber on ADSL. Can I apply for Singtel Fibre Broadband service plans without terminating my existing Singtel Home Broadband ADSL services?\"\n",
    "userInput2 = \"I am currently a SingNet Home Broadband customer on ADSL without any contract. Can I upgrade to Singtel Fibre Broadband? How do I go about doing so?\"\n",
    "userInput3 = \"How do I connect to Wifi?\"\n",
    "phraseVector1 = PhraseVector(userInput1)\n",
    "phraseVector2 = PhraseVector(userInput3)\n",
    "similarityScore  = phraseVector1.CosineSimilarity(phraseVector2.vector)\n",
    "print (\"Similarity Score: \", similarityScore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
